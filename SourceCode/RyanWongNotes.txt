Notes:
	Modified config to take the path using cwd
	Modified Simulator to take in command line arguments if specific
	Modified simulator to produce output file that can output config, time, classification - can be expanded to do other exports
	Change benchmark data -> "Benchmark_Data"
	Wrote naive python code to produce N random configurations: produced 60k & 120k
	Git repository to be uploaded on request
	
	potential: adding function to compute the delta; lets define delta as volume/time?
		Called connectivity
		
	Questions:
		Can I assume that I will always have a log file for a given application, or is this meant to model. ie. if I want to build my neural net, can I preprocess the data..
			ie. connectivity can i derive?
			
		Neural Net Ideas:
		Each input is a node[0:15]
		
	TODO: 
	
	Timing: 52mins for 200 sim -> Roughly 15 sec per sim
			200k sim projected at -> 50000 minutes -> 47 days -_-
				This definitely needs to be distributed across 400 nodes
				
	Parallel python script
	
Week 2:
	Creating script to distribute Simulator over N nodes
		Still need to fix the i/o file parsing and naming issues
			Goal: 3 Types:	1) Connectivity
							2) Log Analysis
							3) NeuralNet Training Data
		ConfigurationFiles for parallel processing must be named as: ParallelConfigurations-NumberOfSamples.txt
			ie. ParallelConfigurations-60000.txt
	!!! Need to add nodeCount back in as sysargv[3] - other ideas to explore include reading from the node argument
        Still need to make hostfile, waiting on richard to do that.
	
    21mins for 600!
	
	TensorFlow: Reading
	DNN: Still unsure

Week 3:
    Simulation Ran for 60k tests, lowest latency I could find was 2.5xxx;
    Will need to run a statistical analysis on it, to get min max med etc. 
    This should be sufficient to get our basic NN started
    
    Need to convert my output file into a tensorflow .csv
        Will be implemented using DataConverter.py which will fuse all the values into one, and quantize the value good/bad/etc.
    
    DNN Classifier - will try 2 hidden layers of 16 nodes ea
    Activation Functions: Either ReLu ( Hot right now) or sigmoid (non-linear)
    
    BUG: When Distributing files the files are not properly being executed
        Fixed 6/16

Week 4:
    Goals:
        Complete Time based analysis:
            1) Using Wait Time
            2) Using Communication Time (Non-Waiting)
        Continue to train and test NN
        Generate larger data and training sets
    
    Explored Logfile preprocessing:
        1) From flow_freq100#2.txt -> It seems like there are many tx that com              with node 1, which then may force us to look more closely at time
            otherwise 1 is a bottleneck that can not be averted
        2) Maybe use a greedy assignment placement first?
        3) Compare with past project



